{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0fcc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyNexus Comprehensive Data Quality Assessment\n",
      "=======================================================\n",
      "Assessment started: 2025-07-05 00:09:01\n",
      "Objective: Validate data quality for energy forecasting and optimization\n",
      "API loading failed: Config file not found\n",
      "Creating comprehensive sample energy data with quality issues for assessment...\n",
      "Introducing realistic data quality issues for assessment...\n",
      "Data source: Generated sample data with intentional quality issues\n",
      "Dataset shape: (1203, 13)\n",
      "Assessment period: 2024-01-01 00:00:00 to 2024-02-19 23:00:00\n",
      "Energy variables for quality assessment: 9\n",
      "Variables: ['energy_demand', 'solar_generation', 'wind_generation', 'natural_gas_generation', 'total_renewable', 'total_generation', 'temperature', 'grid_frequency', 'energy_price']\n",
      "\n",
      "INITIAL DATA QUALITY OVERVIEW:\n",
      "========================================\n",
      "Dataset size: 1,203 rows Ã— 13 columns\n",
      "Total data cells: 15,639\n",
      "Missing cells: 115 (0.7%)\n",
      "Duplicate timestamps: 3\n",
      "\n",
      "Variable Quality Summary:\n",
      "                        Missing_Count  Missing_Percent  Non_Missing_Count  \\\n",
      "energy_demand                     0.0             0.00             1203.0   \n",
      "solar_generation                 24.0             2.00             1179.0   \n",
      "wind_generation                  73.0             6.07             1130.0   \n",
      "natural_gas_generation            0.0             0.00             1203.0   \n",
      "total_renewable                   0.0             0.00             1203.0   \n",
      "total_generation                  0.0             0.00             1203.0   \n",
      "temperature                      18.0             1.50             1185.0   \n",
      "grid_frequency                    0.0             0.00             1203.0   \n",
      "energy_price                      0.0             0.00             1203.0   \n",
      "\n",
      "                        Min_Value  Max_Value  Mean_Value  Std_Value  \\\n",
      "energy_demand              293.26    1337.70      542.24     107.81   \n",
      "solar_generation             0.00     481.52       49.66      57.91   \n",
      "wind_generation            -47.44     188.54       79.28      33.66   \n",
      "natural_gas_generation      63.75     788.96      410.72     124.02   \n",
      "total_renewable             10.00     311.16      128.70      64.50   \n",
      "total_generation           269.05     844.77      537.88     105.70   \n",
      "temperature                  3.93      33.58       19.22       5.69   \n",
      "grid_frequency              49.50      50.50       50.00       0.04   \n",
      "energy_price                22.68      79.72       50.08      10.04   \n",
      "\n",
      "                        Outlier_Count  Outlier_Percent  \n",
      "energy_demand                     5.0             0.42  \n",
      "solar_generation                  2.0             0.17  \n",
      "wind_generation                   8.0             0.71  \n",
      "natural_gas_generation            1.0             0.08  \n",
      "total_renewable                   0.0             0.00  \n",
      "total_generation                  2.0             0.17  \n",
      "temperature                       0.0             0.00  \n",
      "grid_frequency                   12.0             1.00  \n",
      "energy_price                      2.0             0.17  \n",
      "\n",
      "OVERALL QUALITY ASSESSMENT:\n",
      "  Data Completeness: 99.3%\n",
      "  Data Consistency: 99.8%\n",
      "  Average Outlier Rate: 0.3%\n",
      "  Overall Quality Score: 99.5%\n",
      "  Quality Assessment: Excellent - Suitable for advanced modeling\n",
      "Directory structure verified and created if needed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Notebook Introduction and Setup\n",
    "\"\"\"\n",
    "EnergyNexus Data Quality Assessment Notebook\n",
    "Aditya's MSc Project - Comprehensive Data Quality Analysis and Validation\n",
    "\n",
    "NOTEBOOK PURPOSE:\n",
    "This notebook performs comprehensive data quality assessment to ensure the reliability\n",
    "and accuracy of my energy forecasting system. Data quality is fundamental because:\n",
    "\n",
    "1. Poor data quality directly degrades forecasting model performance\n",
    "2. Energy system reliability depends on accurate and consistent data\n",
    "3. Anomalies and outliers can indicate equipment failures or data collection issues\n",
    "4. Data gaps and inconsistencies affect model training and validation\n",
    "5. Quality metrics inform data preprocessing and cleaning strategies\n",
    "\n",
    "MY DATA QUALITY ASSESSMENT STRATEGY:\n",
    "1. Comprehensive missing data analysis and pattern identification\n",
    "2. Outlier detection using multiple statistical and domain-specific methods\n",
    "3. Data consistency validation across temporal and logical constraints\n",
    "4. Data integrity checks for energy balance and physical feasibility\n",
    "5. Temporal continuity assessment for time series modeling requirements\n",
    "6. Data completeness evaluation for different modeling scenarios\n",
    "\n",
    "WHY DATA QUALITY IS CRITICAL FOR MY PROJECT:\n",
    "- LSTM models require consistent, high-quality time series data\n",
    "- Energy optimization depends on accurate generation and demand data\n",
    "- Forecasting accuracy is directly proportional to input data quality\n",
    "- System reliability analysis requires comprehensive historical data\n",
    "- Operational decisions based on poor data can lead to grid instability\n",
    "\n",
    "Author: Aditya Talekar (ec24018@qmul.ac.uk)\n",
    "Supervisor: Saqib Iqbal\n",
    "QMUL MSc Data Science and AI - 2024/25\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# I suppress warnings for clean thesis documentation output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# I configure plotting parameters for publication-quality data quality figures\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set1\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# I add source directory for importing custom data quality modules\n",
    "sys.path.append(os.path.join('..', '..', 'src'))\n",
    "\n",
    "print(\"EnergyNexus Comprehensive Data Quality Assessment\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Assessment started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Objective: Validate data quality for energy forecasting and optimization\")\n",
    "\n",
    "\n",
    "# Cell 2: Data Loading and Initial Quality Overview\n",
    "\"\"\"\n",
    "I load the energy dataset and perform initial quality assessment to understand\n",
    "the scope and nature of potential data quality issues.\n",
    "\n",
    "INITIAL QUALITY ASSESSMENT:\n",
    "- Load complete dataset and validate structure\n",
    "- Calculate basic quality metrics across all variables\n",
    "- Identify critical quality issues requiring immediate attention\n",
    "- Establish baseline quality scores for improvement tracking\n",
    "\"\"\"\n",
    "\n",
    "def load_energy_data():\n",
    "    \"\"\"Load real energy data from APIs or fallback to sample data\"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        import yaml\n",
    "        \n",
    "        # Try to load API configuration\n",
    "        config_path = '../../config/config.yaml'\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path) as f:\n",
    "                config = yaml.safe_load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Config file not found\")\n",
    "        \n",
    "        # 1. Load EIA energy data\n",
    "        print(\"Fetching real energy data from EIA API...\")\n",
    "        eia_url = \"https://api.eia.gov/v2/electricity/rto/region-data/data/\"\n",
    "        params = {\n",
    "            'api_key': config['eia']['api_key'],\n",
    "            'frequency': 'hourly',\n",
    "            'data': ['value'],\n",
    "            'facets': {'type': ['D']},  # Demand data\n",
    "            'start': '2024-01-01',\n",
    "            'end': '2024-03-01',\n",
    "            'sort': [{\"column\": \"period\", \"direction\": \"desc\"}]\n",
    "        }\n",
    "        response = requests.get(eia_url, params=params)\n",
    "        response.raise_for_status()  # Raise error for bad status\n",
    "        eia_data = response.json()['response']['data']\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        energy_df = pd.DataFrame(eia_data)\n",
    "        energy_df['timestamp'] = pd.to_datetime(energy_df['period'])\n",
    "        energy_df.set_index('timestamp', inplace=True)\n",
    "        energy_df.rename(columns={'value': 'energy_demand'}, inplace=True)\n",
    "        \n",
    "        # 2. Load Open-Meteo weather data\n",
    "        print(\"Fetching weather data from Open-Meteo API...\")\n",
    "        weather_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        weather_params = {\n",
    "            'latitude': 51.5074,  # London coordinates\n",
    "            'longitude': -0.1278,\n",
    "            'start_date': energy_df.index.min().strftime('%Y-%m-%d'),\n",
    "            'end_date': energy_df.index.max().strftime('%Y-%m-%d'),\n",
    "            'hourly': 'temperature_2m,relative_humidity_2m,wind_speed_10m'\n",
    "        }\n",
    "        weather_response = requests.get(weather_url, params=weather_params)\n",
    "        weather_response.raise_for_status()\n",
    "        weather_data = weather_response.json()['hourly']\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        weather_df = pd.DataFrame(weather_data)\n",
    "        weather_df['timestamp'] = pd.to_datetime(weather_df['time'])\n",
    "        weather_df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        # 3. Merge datasets\n",
    "        combined_data = pd.merge(energy_df, weather_df, left_index=True, right_index=True, how='inner')\n",
    "        \n",
    "        # 4. Add simulated renewables and price\n",
    "        print(\"Generating renewable and price features...\")\n",
    "        # Solar generation (simulated based on time and weather)\n",
    "        hour_sin = np.sin((combined_data.index.hour - 12) * np.pi/12)\n",
    "        combined_data['solar_generation'] = np.maximum(0, hour_sin * 200 * (1 - combined_data['temperature_2m']/40))\n",
    "        \n",
    "        # Wind generation (based on wind speed)\n",
    "        combined_data['wind_generation'] = combined_data['wind_speed_10m'] * 15\n",
    "        \n",
    "        # Price simulation\n",
    "        demand = combined_data['energy_demand'].values  # Convert to numpy array\n",
    "        solar = combined_data['solar_generation'].values\n",
    "        wind = combined_data['wind_generation'].values\n",
    "        \n",
    "        base_price = 50\n",
    "        demand_factor = (demand - np.mean(demand)) / np.std(demand) * 10\n",
    "        renewable_factor = -((solar + wind) - np.mean(solar + wind)) / np.std(solar + wind) * 8\n",
    "        combined_data['energy_price'] = base_price + demand_factor + renewable_factor + np.random.normal(0, 5, len(demand))\n",
    "        \n",
    "        # Add time features\n",
    "        combined_data['hour'] = combined_data.index.hour\n",
    "        combined_data['day_of_week'] = combined_data.index.dayofweek\n",
    "        combined_data['month'] = combined_data.index.month\n",
    "        combined_data['is_weekend'] = combined_data['day_of_week'] >= 5\n",
    "        combined_data['is_business_hour'] = (combined_data['hour'] >= 8) & (combined_data['hour'] <= 18)\n",
    "        combined_data['total_renewable'] = combined_data['solar_generation'] + combined_data['wind_generation']\n",
    "        \n",
    "        print(\"Successfully loaded real energy and weather data via APIs\")\n",
    "        return combined_data, \"Real API data\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API loading failed: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# I attempt to load processed energy data, creating comprehensive sample if needed\n",
    "try:\n",
    "    # First try to load from the processed directory\n",
    "    processed_file = '../../data/processed/test_cleaned_energy_data.csv'\n",
    "    if os.path.exists(processed_file):\n",
    "        energy_data = pd.read_csv(processed_file, parse_dates=[0], index_col=0)\n",
    "        print(\"Successfully loaded processed energy dataset\")\n",
    "        data_source = \"Processed pipeline data\"\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Processed file not found\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    # Try loading from API\n",
    "    api_result, api_source = load_energy_data()\n",
    "    \n",
    "    if api_result is not None:\n",
    "        energy_data = api_result\n",
    "        data_source = api_source\n",
    "    else:\n",
    "        print(\"Creating comprehensive sample energy data with quality issues for assessment...\")\n",
    "        \n",
    "        # I generate realistic energy data with intentional quality issues for testing\n",
    "        np.random.seed(42)\n",
    "        hours = 24 * 50  # 50 days for comprehensive quality assessment\n",
    "        dates = pd.date_range(start='2024-01-01', periods=hours, freq='H')\n",
    "        \n",
    "        # I create base energy system data\n",
    "        time_hours = np.arange(hours)\n",
    "        \n",
    "        # Base temperature pattern\n",
    "        temperature = 15 + 10 * np.sin(2 * np.pi * dates.dayofyear / 365) + \\\n",
    "                      6 * np.sin((time_hours % 24 - 14) * 2 * np.pi / 24) + \\\n",
    "                      np.random.normal(0, 3, hours)\n",
    "        \n",
    "        # Solar generation with realistic patterns\n",
    "        solar_elevation = np.maximum(0, np.sin((time_hours % 24 - 12) * np.pi / 12))\n",
    "        cloud_factor = np.random.uniform(0.6, 1.0, hours)\n",
    "        solar_generation = solar_elevation * cloud_factor * 180 + np.random.normal(0, 12, hours)\n",
    "        solar_generation = np.maximum(0, solar_generation)\n",
    "        \n",
    "        # Wind generation with persistence\n",
    "        wind_base = 80 + 30 * np.sin(2 * np.pi * time_hours / (24 * 8))\n",
    "        wind_noise = np.random.normal(0, 25, hours)\n",
    "        wind_generation = wind_base + wind_noise\n",
    "        wind_generation = np.maximum(10, wind_generation)\n",
    "        \n",
    "        # Energy demand with multiple components\n",
    "        demand_base = 450\n",
    "        daily_pattern = 200 * np.maximum(0, np.sin((time_hours % 24 - 6) * np.pi / 12))\n",
    "        weekly_pattern = 80 * np.sin((time_hours % (24*7)) * 2 * np.pi / (24*7))\n",
    "        heating_demand = np.maximum(0, (15 - temperature) * 12)\n",
    "        cooling_demand = np.maximum(0, (temperature - 22) * 15)\n",
    "        energy_demand = (demand_base + daily_pattern + weekly_pattern + \n",
    "                        heating_demand + cooling_demand + np.random.normal(0, 30, hours))\n",
    "        energy_demand = np.maximum(250, energy_demand)\n",
    "        \n",
    "        # Natural gas generation following demand\n",
    "        natural_gas_generation = np.maximum(0, energy_demand - solar_generation - wind_generation + \n",
    "                                           np.random.normal(0, 20, hours))\n",
    "        \n",
    "        # Grid frequency based on supply-demand balance\n",
    "        supply_total = solar_generation + wind_generation + natural_gas_generation\n",
    "        grid_frequency = 50.0 + (supply_total - energy_demand) * 0.0005 + np.random.normal(0, 0.02, hours)\n",
    "        grid_frequency = np.clip(grid_frequency, 49.8, 50.2)\n",
    "        \n",
    "        # Energy price based on demand and supply - FIXED VERSION\n",
    "        base_price = 50\n",
    "        demand_factor = (energy_demand - np.mean(energy_demand)) / np.std(energy_demand) * 8\n",
    "        renewable_factor = -((solar_generation + wind_generation) - np.mean(solar_generation + wind_generation)) / np.std(solar_generation + wind_generation) * 5\n",
    "        energy_price = base_price + demand_factor + renewable_factor + np.random.normal(0, 3, hours)\n",
    "        energy_price = np.maximum(0, energy_price)\n",
    "        \n",
    "        # I create the initial clean dataset\n",
    "        energy_data = pd.DataFrame({\n",
    "            'energy_demand': energy_demand,\n",
    "            'solar_generation': solar_generation,\n",
    "            'wind_generation': wind_generation,\n",
    "            'natural_gas_generation': natural_gas_generation,\n",
    "            'total_renewable': solar_generation + wind_generation,\n",
    "            'total_generation': solar_generation + wind_generation + natural_gas_generation,\n",
    "            'temperature': temperature,\n",
    "            'grid_frequency': grid_frequency,\n",
    "            'energy_price': energy_price,\n",
    "            'hour': dates.hour,\n",
    "            'day_of_week': dates.dayofweek,\n",
    "            'month': dates.month,\n",
    "            'is_weekend': dates.dayofweek >= 5\n",
    "        }, index=dates)\n",
    "        \n",
    "        # I intentionally introduce various data quality issues for testing\n",
    "        print(\"Introducing realistic data quality issues for assessment...\")\n",
    "        \n",
    "        # 1. Missing data patterns (equipment failures, communication issues)\n",
    "        # Random missing values (sensor failures)\n",
    "        missing_indices_random = np.random.choice(energy_data.index, size=int(len(energy_data) * 0.02), replace=False)\n",
    "        energy_data.loc[missing_indices_random, 'solar_generation'] = np.nan\n",
    "        \n",
    "        # Consecutive missing periods (maintenance windows)\n",
    "        maintenance_start = np.random.choice(energy_data.index[:-48], size=3)\n",
    "        for start_idx in maintenance_start:\n",
    "            start_loc = energy_data.index.get_loc(start_idx)\n",
    "            end_loc = min(start_loc + 24, len(energy_data) - 1)  # 24-hour maintenance\n",
    "            energy_data.iloc[start_loc:end_loc, energy_data.columns.get_loc('wind_generation')] = np.nan\n",
    "        \n",
    "        # Weather station outages\n",
    "        weather_outage_indices = np.random.choice(energy_data.index, size=int(len(energy_data) * 0.015), replace=False)\n",
    "        energy_data.loc[weather_outage_indices, 'temperature'] = np.nan\n",
    "        \n",
    "        # 2. Outliers and anomalies\n",
    "        # Extreme solar spikes (sensor malfunctions)\n",
    "        spike_indices = np.random.choice(energy_data.index[energy_data['solar_generation'] > 0], size=5)\n",
    "        energy_data.loc[spike_indices, 'solar_generation'] *= 3  # 300% spikes\n",
    "        \n",
    "        # Negative values (sensor calibration errors)\n",
    "        negative_indices = np.random.choice(energy_data.index, size=8)\n",
    "        energy_data.loc[negative_indices, 'wind_generation'] = -np.random.uniform(10, 50, len(negative_indices))\n",
    "        \n",
    "        # Extreme demand spikes (data transmission errors)\n",
    "        demand_spike_indices = np.random.choice(energy_data.index, size=3)\n",
    "        energy_data.loc[demand_spike_indices, 'energy_demand'] *= 2.5\n",
    "        \n",
    "        # Frequency outliers (grid events)\n",
    "        freq_outlier_indices = np.random.choice(energy_data.index, size=6)\n",
    "        energy_data.loc[freq_outlier_indices, 'grid_frequency'] = np.random.choice([49.5, 50.5], len(freq_outlier_indices))\n",
    "        \n",
    "        # 3. Data inconsistencies\n",
    "        # Total generation not matching sum of components\n",
    "        inconsistent_indices = np.random.choice(energy_data.index, size=12)\n",
    "        energy_data.loc[inconsistent_indices, 'total_generation'] *= 0.7  # 30% underreporting\n",
    "        \n",
    "        # Impossible combinations (generation without solar irradiance)\n",
    "        night_indices = energy_data[energy_data['hour'].isin([0, 1, 2, 3, 4, 5, 22, 23])].index\n",
    "        impossible_solar_indices = np.random.choice(night_indices, size=4)\n",
    "        energy_data.loc[impossible_solar_indices, 'solar_generation'] = np.random.uniform(50, 100, len(impossible_solar_indices))\n",
    "        \n",
    "        # 4. Timestamp issues\n",
    "        # Duplicate timestamps (create a few duplicated rows)\n",
    "        duplicate_indices = np.random.choice(energy_data.index, size=3)\n",
    "        for dup_idx in duplicate_indices:\n",
    "            duplicate_row = energy_data.loc[dup_idx].copy()\n",
    "            energy_data = pd.concat([energy_data, duplicate_row.to_frame().T])\n",
    "        \n",
    "        # I sort to handle duplicates properly\n",
    "        energy_data = energy_data.sort_index()\n",
    "        \n",
    "        data_source = \"Generated sample data with intentional quality issues\"\n",
    "\n",
    "print(f\"Data source: {data_source}\")\n",
    "print(f\"Dataset shape: {energy_data.shape}\")\n",
    "print(f\"Assessment period: {energy_data.index.min()} to {energy_data.index.max()}\")\n",
    "\n",
    "# I identify energy variables for quality assessment\n",
    "energy_variables = [col for col in energy_data.columns \n",
    "                   if any(keyword in col.lower() for keyword in \n",
    "                         ['generation', 'demand', 'renewable', 'frequency', 'price', 'temperature'])]\n",
    "\n",
    "print(f\"Energy variables for quality assessment: {len(energy_variables)}\")\n",
    "print(f\"Variables: {energy_variables}\")\n",
    "\n",
    "# I calculate initial quality overview\n",
    "print(f\"\\nINITIAL DATA QUALITY OVERVIEW:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "total_cells = energy_data.shape[0] * energy_data.shape[1]\n",
    "missing_cells = energy_data.isnull().sum().sum()\n",
    "duplicate_rows = energy_data.index.duplicated().sum()\n",
    "\n",
    "print(f\"Dataset size: {energy_data.shape[0]:,} rows Ã— {energy_data.shape[1]} columns\")\n",
    "print(f\"Total data cells: {total_cells:,}\")\n",
    "print(f\"Missing cells: {missing_cells:,} ({missing_cells/total_cells*100:.1f}%)\")\n",
    "print(f\"Duplicate timestamps: {duplicate_rows}\")\n",
    "\n",
    "# I calculate variable-specific quality metrics\n",
    "variable_quality_summary = pd.DataFrame(index=energy_variables)\n",
    "\n",
    "for var in energy_variables:\n",
    "    if var in energy_data.columns:\n",
    "        data_series = energy_data[var]\n",
    "        \n",
    "        # Basic quality metrics\n",
    "        variable_quality_summary.loc[var, 'Missing_Count'] = data_series.isnull().sum()\n",
    "        variable_quality_summary.loc[var, 'Missing_Percent'] = (data_series.isnull().sum() / len(data_series)) * 100\n",
    "        variable_quality_summary.loc[var, 'Non_Missing_Count'] = data_series.count()\n",
    "        \n",
    "        # Data range and distribution\n",
    "        if data_series.count() > 0:\n",
    "            variable_quality_summary.loc[var, 'Min_Value'] = data_series.min()\n",
    "            variable_quality_summary.loc[var, 'Max_Value'] = data_series.max()\n",
    "            variable_quality_summary.loc[var, 'Mean_Value'] = data_series.mean()\n",
    "            variable_quality_summary.loc[var, 'Std_Value'] = data_series.std()\n",
    "            \n",
    "            # Outlier detection using IQR method\n",
    "            Q1 = data_series.quantile(0.25)\n",
    "            Q3 = data_series.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outlier_count = ((data_series < (Q1 - 1.5 * IQR)) | (data_series > (Q3 + 1.5 * IQR))).sum()\n",
    "            variable_quality_summary.loc[var, 'Outlier_Count'] = outlier_count\n",
    "            variable_quality_summary.loc[var, 'Outlier_Percent'] = (outlier_count / data_series.count()) * 100\n",
    "\n",
    "print(f\"\\nVariable Quality Summary:\")\n",
    "print(variable_quality_summary.round(2))\n",
    "\n",
    "# I calculate overall quality score\n",
    "overall_quality_metrics = {\n",
    "    'completeness_score': (1 - missing_cells / total_cells) * 100,\n",
    "    'consistency_score': (1 - duplicate_rows / len(energy_data)) * 100,\n",
    "    'average_outlier_rate': variable_quality_summary['Outlier_Percent'].mean()\n",
    "}\n",
    "\n",
    "overall_quality_score = (overall_quality_metrics['completeness_score'] * 0.4 + \n",
    "                         overall_quality_metrics['consistency_score'] * 0.3 + \n",
    "                         (100 - overall_quality_metrics['average_outlier_rate']) * 0.3)\n",
    "\n",
    "print(f\"\\nOVERALL QUALITY ASSESSMENT:\")\n",
    "print(f\"  Data Completeness: {overall_quality_metrics['completeness_score']:.1f}%\")\n",
    "print(f\"  Data Consistency: {overall_quality_metrics['consistency_score']:.1f}%\")\n",
    "print(f\"  Average Outlier Rate: {overall_quality_metrics['average_outlier_rate']:.1f}%\")\n",
    "print(f\"  Overall Quality Score: {overall_quality_score:.1f}%\")\n",
    "\n",
    "if overall_quality_score >= 90:\n",
    "    quality_assessment = \"Excellent - Suitable for advanced modeling\"\n",
    "elif overall_quality_score >= 80:\n",
    "    quality_assessment = \"Good - Minor preprocessing needed\"\n",
    "elif overall_quality_score >= 70:\n",
    "    quality_assessment = \"Acceptable - Moderate preprocessing required\"\n",
    "else:\n",
    "    quality_assessment = \"Poor - Significant preprocessing required\"\n",
    "\n",
    "print(f\"  Quality Assessment: {quality_assessment}\")\n",
    "\n",
    "# Cell 3: Create necessary directories\n",
    "\"\"\"\n",
    "I ensure required directories exist for saving plots and results\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "results_dir = '../../results'\n",
    "plots_dir = '../../results/plots'\n",
    "\n",
    "for directory in [results_dir, plots_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "print(\"Directory structure verified and created if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2b5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
